import express from 'express';
import { WebSocketServer } from 'ws';
import fs from 'fs';
import path from 'path';
import { tmpdir } from 'os';
import { OpenAI } from 'openai';
import dotenv from 'dotenv';
import admin from 'firebase-admin';
dotenv.config();

// Initialize Firebase Admin
try {
Â  Â  const serviceAccount = JSON.parse(process.env.FIREBASE_CREDENTIALS);
Â  Â  admin.initializeApp({
Â  Â  Â  Â  credential: admin.credential.cert(serviceAccount)
Â  Â  });
Â  Â  console.log('[Firebase] Admin SDK initialized successfully.');
} catch (error) {
Â  Â  console.error('[Firebase] Failed to initialize Admin SDK. Check your FIREBASE_CREDENTIALS environment variable.', error.message);
}
const db = admin.firestore();

const app = express();
app.use(express.json());

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
const wss = new WebSocketServer({ noServer: true });

function generateSystemPrompt(config) {
Â  Â  const safeConfig = (config && typeof config === 'object') ? config : {};
Â  Â  const agentName = safeConfig.agent_name || 'Rohan';
Â  Â  const companyName = safeConfig.company_name || 'the company';
Â  Â  const productInfo = safeConfig.product_service_info || 'our products and services';
Â  Â  let issuesAndSolutions = (safeConfig.faqs && Array.isArray(safeConfig.faqs) && safeConfig.faqs.length > 0)
Â  Â  Â  Â  ? safeConfig.faqs.filter(faq => faq && faq.issue && faq.solution).map(faq => `Issue: ${faq.issue}\nSolution: ${faq.solution}`).join('\n\n')
Â  Â  Â  Â  : 'No common issues provided.';
Â  Â  return `You are a customer support live chat agent for ${companyName}. Your name is ${agentName}. You are friendly, professional, and empathetic. Your primary goal is to resolve customer issues efficiently and leave them with a positive impression of the company. Speak like a human support agent, not an AI. This means: Use short, clear sentences. Employ a conversational and friendly tone. Use contractions like "I'm," "you're," and "that's." Incorporate emojis where appropriate to convey tone, but do not overuse them. Be concise. Get straight to the point without unnecessary fluff or lengthy explanations. Your Core Responsibilities: Acknowledge and Empathize. Gather Information. Provide Solutions based on the company-specific information provided below. If you don't know the answer, politely ask the customer to hold while you check. Closing the Conversation: Once the issue is resolved, ask if there is anything else you can help with and wish them a good day. Company-Specific Information: Product/Service: ${productInfo}. Common Issues & Solutions:\n${issuesAndSolutions}. Escalation Protocol: If the user asks to speak to a human, a human agent, or any variation of this, you MUST immediately respond with **ONLY** the following special command: [HUMAN_HANDOFF_REQUESTED] - do not add any other text or pleasantries around it.`;
}

async function analyzeConversation(history) {
Â  Â  const transcript = history
Â  Â  Â  Â  .filter(msg => msg.role === 'user' || msg.role === 'assistant')
Â  Â  Â  Â  .map(msg => `${msg.role}: ${msg.content}`)
Â  Â  Â  Â  .join('\n');

Â  Â  if (!transcript) {
Â  Â  Â  Â  return { sentiment: 'N/A', subject: 'Empty Conversation', resolution_status: 'N/A' };
Â  Â  }

Â  Â  try {
Â  Â  Â  Â  const analysisPrompt = `Analyze the following chat transcript.Â 
Â  Â  Â  Â  1. Determine the user's overall sentiment (one word: Positive, Negative, or Neutral).
Â  Â  Â  Â  2. Create a concise subject line (5 words or less).
Â  Â  Â  Â  3. Determine if the user's issue was resolved (one word: Resolved or Unresolved).
Â  Â  Â  Â Â 
Â  Â  Â  Â  Transcript:
Â  Â  Â  Â  ${transcript}

Â  Â  Â  Â  Return your answer as a single, valid JSON object with three keys: "sentiment", "subject", and "resolution_status".`;

Â  Â  Â  Â  const response = await openai.chat.completions.create({
Â  Â  Â  Â  Â  Â  model: 'gpt-4o-mini',
Â  Â  Â  Â  Â  Â  messages: [{ role: 'system', content: analysisPrompt }],
Â  Â  Â  Â  Â  Â  response_format: { type: "json_object" }
Â  Â  Â  Â  });

Â  Â  Â  Â  const analysis = JSON.parse(response.choices[0].message.content);
Â  Â  Â  Â  return {
Â  Â  Â  Â  Â  Â  sentiment: analysis.sentiment || 'Unknown',
Â  Â  Â  Â  Â  Â  subject: analysis.subject || 'No Subject',
Â  Â  Â  Â  Â  Â  resolution_status: analysis.resolution_status || 'Unknown'
Â  Â  Â  Â  };
Â  Â  } catch (error) {
Â  Â  Â  Â  console.error('[AI Analysis] Failed to analyze conversation:', error);
Â  Â  Â  Â  return { sentiment: 'Error', subject: 'Analysis Failed', resolution_status: 'Error' };
Â  Â  }
}

function slugify(text) {
Â  return text
Â  Â  .toString()
Â  Â  .toLowerCase()
Â  Â  .trim()
Â  Â  .replace(/\s+/g, '-')
Â  Â  .replace(/[^\w\-]+/g, '')
Â  Â  .replace(/\-\-+/g, '-');
}

async function logConversation(history, interactionType, origin, startTime) {
Â  Â  if (!db) {
Â  Â  Â  Â  console.log('[Firestore] Database not initialized. Skipping log.');
Â  Â  Â  Â  return;
Â  Â  }
Â  Â  if (history.length <= 2) {
Â  Â  Â  Â  console.log('[Firestore] Conversation too short. Skipping log.');
Â  Â  Â  Â  return;
Â  Â  }

Â  Â  try {
Â  Â  Â  Â  const { sentiment, subject, resolution_status } = await analyzeConversation(history);
Â  Â  Â  Â Â 
Â  Â  Â  Â  const fullTranscript = history
Â  Â  Â  Â  Â  Â  .filter(msg => msg.role !== 'system')
Â  Â  Â  Â  Â  Â  .map(msg => `[${msg.role}] ${msg.content}`)
Â  Â  Â  Â  Â  Â  .join('\n---\n');
Â  Â  Â  Â Â 
Â  Â  Â  Â  const date = new Date(startTime);
Â  Â  Â  Â  const timestamp = `${date.getFullYear()}${(date.getMonth()+1).toString().padStart(2, '0')}${date.getDate().toString().padStart(2, '0')}-${date.getHours().toString().padStart(2, '0')}${date.getMinutes().toString().padStart(2, '0')}`;
Â  Â  Â  Â  const subjectSlug = slugify(subject);
Â  Â  Â  Â  const docId = `${timestamp}-${subjectSlug}`;

Â  Â  Â  Â  const conversationData = {
Â  Â  Â  Â  Â  Â  interaction_type: interactionType,
Â  Â  Â  Â  Â  Â  origin: origin || 'unknown',
Â  Â  Â  Â  Â  Â  start_time: startTime,
Â  Â  Â  Â  Â  Â  end_time: admin.firestore.FieldValue.serverTimestamp(),
Â  Â  Â  Â  Â  Â  sentiment: sentiment,
Â  Â  Â  Â  Â  Â  subject: subject,
Â  Â  Â  Â  Â  Â  transcript: fullTranscript,
Â  Â  Â  Â  Â  Â  resolution_status: resolution_status
Â  Â  Â  Â  };

Â  Â  Â  Â  await db.collection('conversations').doc(docId).set(conversationData);
Â  Â  Â  Â Â 
Â  Â  Â  Â  console.log(`[Firestore] Logged conversation with ID: "${docId}"`);
Â  Â  } catch (error) {
Â  Â  Â  Â  console.error('[Firestore] Failed to log conversation:', error.message);
Â  Â  }
}

async function transcribeWhisper(audioBuffer, langCode = 'en') {
Â  Â  const tempFilePath = path.join(tmpdir(), `audio_${Date.now()}.webm`);
Â  Â  try {
Â  Â  Â  Â  await fs.promises.writeFile(tempFilePath, audioBuffer);
Â  Â  Â  Â  const fileStream = fs.createReadStream(tempFilePath);
Â  Â  Â  Â  const response = await openai.audio.transcriptions.create({ file: fileStream, model: 'whisper-1', language: langCode });
Â  Â  Â  Â  return response.text;
Â  Â  } catch (error) {
Â  Â  Â  Â  console.error('[Whisper] Transcription error:', error);
Â  Â  Â  Â  throw error;
Â  Â  } finally {
Â  Â  Â  Â  await fs.promises.unlink(tempFilePath).catch(err => console.error("Error deleting temp file:", err));
Â  Â  }
}

async function getAIReply(history) {
Â  Â  const chatCompletion = await openai.chat.completions.create({ model: 'gpt-4o-mini', messages: history });
Â  Â  return chatCompletion.choices[0].message.content;
}

async function speakText(text, ws, voice = 'nova') {
Â  Â  if (!text || text.trim() === '') {
Â  Â  Â  Â  console.log('[OpenAI TTS] Skipping empty text for speech synthesis.');
Â  Â  Â  Â  return;
Â  Â  }
Â  Â  try {
Â  Â  Â  Â  const mp3 = await openai.audio.speech.create({
Â  Â  Â  Â  Â  Â  model: "tts-1",
Â  Â  Â  Â  Â  Â  voice: voice,
Â  Â  Â  Â  Â  Â  input: text,
Â  Â  Â  Â  Â  Â  speed: 1.2
Â  Â  Â  Â  });

Â  Â  Â  Â  const buffer = Buffer.from(await mp3.arrayBuffer());
Â  Â  Â  Â Â 
Â  Â  Â  Â  if (ws.readyState === 1) {
Â  Â  Â  Â  Â  Â  ws.send(buffer);
Â  Â  Â  Â  }
Â  Â  } catch (error) {
Â  Â  Â  Â  console.error('[OpenAI TTS] Synthesis error:', error);
Â  Â  }
}

const ipConnections = new Map();
const MAX_CONNECTIONS_PER_IP = 3;
const MAX_AUDIO_BUFFER_SIZE_MB = 20;

wss.on('connection', (ws, req) => {
Â  Â  const ip = req.socket.remoteAddress;
Â  Â  console.log(`[WS] New connection attempt from IP: ${ip}`);

Â  Â  const currentConnections = ipConnections.get(ip) || 0;
Â  Â  if (currentConnections >= MAX_CONNECTIONS_PER_IP) {
Â  Â  Â  Â  console.log(`[AUTH] IP ${ip} exceeded max connection limit. Connection rejected. ğŸ›‘`);
Â  Â  Â  Â  ws.terminate();
Â  Â  Â  Â  return;
Â  Â  }
Â  Â  ipConnections.set(ip, currentConnections + 1);
Â  Â  console.log(`[WS] Connection from ${ip} accepted. Current connections: ${currentConnections + 1}`);

Â  Â  let audioBufferArray = [];
Â  Â  let currentAudioBufferSize = 0;
Â  Â  let connectionMode = 'text';
Â  Â  let currentLanguage = 'en';
Â  Â  let conversationHistory = [];
Â  Â  let agentName = 'AI Support';
Â  Â  let ttsVoice = 'nova';
Â  Â  const origin = req.headers.origin;
Â  Â  const startTime = new Date();

Â  Â  ws.on('message', async (message) => {
Â  Â  Â  Â  let isCommand = false;
Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  if (Buffer.isBuffer(message)) {
Â  Â  Â  Â  Â  Â  Â  Â  currentAudioBufferSize += message.length;
Â  Â  Â  Â  Â  Â  Â  Â  if (currentAudioBufferSize > MAX_AUDIO_BUFFER_SIZE_MB * 1024 * 1024) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  console.log(`[AUTH] Audio buffer limit exceeded for IP ${ip}. Terminating connection.`);
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ws.terminate();
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return;
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  const data = JSON.parse(message.toString());
Â  Â  Â  Â  Â  Â  isCommand = true;
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if (data.type === 'CONFIG') {
Â  Â  Â  Â  Â  Â  Â  Â  const configData = data.data.config || {};
Â  Â  Â  Â  Â  Â  Â  Â  agentName = configData.agent_name || 'Alex';
Â  Â  Â  Â  Â  Â  Â  Â  ttsVoice = configData.tts_voice || 'nova';
Â  Â  Â  Â  Â  Â  Â  Â  const basePrompt = generateSystemPrompt(configData);
Â  Â  Â  Â  Â  Â  Â  Â  conversationHistory = [{ role: 'system', content: `${basePrompt}\nYour name is ${agentName}.` }];
Â  Â  Â  Â  Â  Â  Â  Â  const proactiveEnabled = configData.proactive_enabled === 'on';
Â  Â  Â  Â  Â  Â  Â  Â  const welcomeMessage = proactiveEnabled ? (configData.proactive_message || `Hi! I'm ${agentName}. Let me know if you need help with anything.`) : `Hi there! My name is ${agentName}. How can I help you today? ğŸ‘‹`;
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  if (ws.readyState === 1) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ws.send(JSON.stringify({ type: 'AI_RESPONSE', text: welcomeMessage }));
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  console.log(`[WS] Config received. Agent: ${agentName}. Voice: ${ttsVoice}.`);
Â  Â  Â  Â  Â  Â  Â  Â  return;
Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  if (conversationHistory.length === 0) {
Â  Â  Â  Â  Â  Â  Â  Â  console.log('[WS] Ignoring message: Configuration not yet received.');
Â  Â  Â  Â  Â  Â  Â  Â  return;
Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  // ** NEW: Handle Human Handoff Request **
Â  Â  Â  Â  Â  Â  if (data.type === 'REQUEST_HUMAN_HANDOFF') {
Â  Â  Â  Â  Â  Â  Â  Â  console.log('[HANDOFF] User requested human agent. Simulating ticket creation.');
Â  Â  Â  Â  Â  Â  Â  Â  conversationHistory.push({ role: 'user', content: 'User requested to speak with a human agent.' });
Â  Â  Â  Â  Â  Â  Â  Â  const handoffMessage = "I've created a ticket for you, and one of our human agents will be in touch shortly. Please let me know if there's anything else I can help with in the meantime.";
Â  Â  Â  Â  Â  Â  Â  Â  conversationHistory.push({ role: 'assistant', content: handoffMessage });
Â  Â  Â  Â  Â  Â  Â  Â  ws.send(JSON.stringify({ type: 'AI_RESPONSE', text: handoffMessage }));
Â  Â  Â  Â  Â  Â  Â  Â  return;
Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  let transcript = '';

Â  Â  Â  Â  Â  Â  if (data.type === 'SET_LANGUAGE') {
Â  Â  Â  Â  Â  Â  Â  Â  currentLanguage = data.language || 'en';
Â  Â  Â  Â  Â  Â  Â  Â  console.log(`[WS] Transcription language set to: ${currentLanguage}`);
Â  Â  Â  Â  Â  Â  Â  Â  return;
Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  if (data.type === 'INIT_VOICE') { connectionMode = 'voice'; return; }
Â  Â  Â  Â  Â  Â  if (data.type === 'END_VOICE') { connectionMode = 'text'; return; }

Â  Â  Â  Â  Â  Â  if (data.type === 'TEXT_MESSAGE') {
Â  Â  Â  Â  Â  Â  Â  Â  transcript = data.text;
Â  Â  Â  Â  Â  Â  } else if (data.type === 'END_OF_STREAM') {
Â  Â  Â  Â  Â  Â  Â  Â  if (audioBufferArray.length === 0) return;
Â  Â  Â  Â  Â  Â  Â  Â  const completeAudioBuffer = Buffer.concat(audioBufferArray);
Â  Â  Â  Â  Â  Â  Â  Â  audioBufferArray = [];
Â  Â  Â  Â  Â  Â  Â  Â  currentAudioBufferSize = 0;
Â  Â  Â  Â  Â  Â  Â  Â  transcript = await transcribeWhisper(completeAudioBuffer, currentLanguage);
Â  Â  Â  Â  Â  Â  Â  Â  if (transcript && transcript.trim() && ws.readyState === 1) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ws.send(JSON.stringify({ type: 'USER_TRANSCRIPT', text: transcript }));
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  if (transcript && transcript.trim()) {
Â  Â  Â  Â  Â  Â  Â  Â  conversationHistory.push({ role: 'user', content: transcript });
Â  Â  Â  Â  Â  Â  Â  Â  const reply = await getAIReply(conversationHistory);
Â  Â  Â  Â  Â  Â  Â  Â  conversationHistory.push({ role: 'assistant', content: reply });

Â  Â  Â  Â  Â  Â  Â  Â  if (reply.includes('[HUMAN_HANDOFF_REQUESTED]')) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ws.send(JSON.stringify({ type: 'HANDOFF_TRIGGERED' }));
Â  Â  Â  Â  Â  Â  Â  Â  } else if (connectionMode === 'voice') {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ws.send(JSON.stringify({ type: 'AI_RESPONSE_PENDING_AUDIO', text: reply }));
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  await speakText(reply, ws, ttsVoice);
Â  Â  Â  Â  Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ws.send(JSON.stringify({ type: 'AI_IS_TYPING' }));
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  setTimeout(() => {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (ws.readyState === 1) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ws.send(JSON.stringify({ type: 'AI_RESPONSE', text: reply }));
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }, 750);
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  } catch (error) {
Â  Â  Â  Â  Â  Â  if (!isCommand && Buffer.isBuffer(message)) {
Â  Â  Â  Â  Â  Â  Â  Â  audioBufferArray.push(message);
Â  Â  Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  Â  Â  console.error('[Process] Error processing command:', error);
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  }
Â  Â  });

Â  Â  ws.on('close', async () => {
Â  Â  Â  Â  console.log(`[WS] Connection from IP ${ip} closed.`);
Â  Â  Â  Â  const connections = (ipConnections.get(ip) || 1) - 1;
Â  Â  Â  Â  if (connections === 0) {
Â  Â  Â  Â  Â  Â  ipConnections.delete(ip);
Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  ipConnections.set(ip, connections);
Â  Â  Â  Â  }
Â  Â  Â  Â  await logConversation(conversationHistory, connectionMode, origin, startTime);
Â  Â  });

Â  Â  ws.on('error', (err) => console.error('[WS] Connection error:', err));
});

const server = app.listen(process.env.PORT || 3000, () => console.log(`[HTTP] Server listening on port ${process.env.PORT || 3000}`));

server.on('upgrade', (req, socket, head) => {
Â  Â  const origin = req.headers.origin;
Â  Â  const allowedOrigins = (process.env.ALLOWED_ORIGINS || '').split(',');
Â  Â  if (allowedOrigins.includes(origin)) {
Â  Â  Â  Â  wss.handleUpgrade(req, socket, head, (ws) => {
Â  Â  Â  Â  Â  Â  wss.emit('connection', ws, req);
Â  Â  Â  Â  });
Â  Â  } else {
Â  Â  Â  Â  console.log(`[AUTH] Connection from origin "${origin}" rejected. âŒ`);
Â  Â  Â  Â  socket.destroy();
Â  Â  }
});
